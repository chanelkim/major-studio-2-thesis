{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# source: HaoChe Hung (2024)\n",
    "\n",
    "## About: brute method alternative to two part Smithsonian API data gathering\n",
    "### Smithsonian API approach: \n",
    "part 1 - edan code, part 2 - derive image url from edan codes\n",
    "### Brute approach: \n",
    "scrape for image urls (and edan codes) after conducting search from https://www.si.edu/openaccess\n",
    "\n",
    "Note: next step, add scripts for retrieving edan codes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ignore unimporant system warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# We will use Pandas, Numpy, and Matplotlib which is a package for visualization with Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load a required package \n",
    "# This is a library for accessing and parsing data through URLs\n",
    "from urllib.parse import urlencode\n",
    "import urllib.request, json \n",
    "from bs4 import BeautifulSoup # for web scraping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # visualization styling package\n",
    "\n",
    "# A magic functin that renders the figure in a notebook \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## links\n",
    "\n",
    "### original sets for Richard The\n",
    "butterfly \n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=butterfly&edan_fq%5B0%5D=set_name:%22Specimen%20Inventory%22&edan_fq%5B1%5D=media_usage:%22CC0%22\n",
    "\n",
    "bug \n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=bug&edan_fq%5B0%5D=set_name:%22Specimen%20Inventory%22&edan_fq%5B1%5D=media_usage:%22CC0%22\n",
    "\n",
    "fish\n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=fish&edan_fq%5B0%5D=set_name:%22Fish%20Images%22&edan_fq%5B1%5D=media_usage:%22CC0%22\n",
    "\n",
    "orchid\n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=orchid&edan_fq%5B0%5D=topic:%22Orchids%22&edan_fq%5B1%5D=object_type:%22Living%20botanical%20specimens%22&edan_fq%5B2%5D=set_name:%22Smithsonian%20Gardens%20Orchid%20Collection%22&edan_fq%5B3%5D=media_usage:%22CC0%22\n",
    "\n",
    "starfish\n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=starfish&oa=1&edan_fq%5B0%5D=media_usage:CC0\n",
    "\n",
    "wasp\n",
    "https://www.si.edu/search/all?page={page-1}&edan_q=wasp&edan_fq%5B0%5D=data_source:%22NMNH%20-%20Education%20%26%20Outreach%22&edan_fq%5B1%5D=media_usage:%22CC0%22\n",
    "\n",
    "mineral\n",
    "https://www.si.edu/search/collection-images?edan_q=mineral&edan_fq%5B0%5D=object_type:%22Education%20and%20Outreach%20collections%22&edan_fq%5B1%5D=media_usage:%22CC0%22\n",
    "\n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=mineral&edan_fq%5B0%5D=object_type:%22Education%20and%20Outreach%20collections%22&edan_fq%5B1%5D=media_usage:%22CC0%22\n",
    "\n",
    "laelia\n",
    "https://www.si.edu/search/collection-images?edan_q=laelia&oa=1&edan_fq%5B0%5D=media_usage:CC0\n",
    "\n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=laelia&oa=1&edan_fq%5B0%5D=media_usage:CC0\n",
    "\n",
    "### test sets for IoAD\n",
    "clay (page 1)\n",
    "https://www.si.edu/search/collection-images?edan_q=clay&oa=1&edan_fq%5B0%5D=media_usage:CC0\n",
    "\n",
    "clay (page 2+)\n",
    "https://www.si.edu/search/collection-images?page={page-1}&edan_q=clay&oa=1&edan_fq%5B0%5D=media_usage:CC0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.si.edu/search/collection-images?edan_q=bug&edan_fq%5B0%5D=set_name:%22Specimen%20Inventory%22&edan_fq%5B1%5D=media_usage:%22CC0%22'\n",
    "# response = urllib.request.urlopen(url)\n",
    "# html = response.read()\n",
    "# mystr = html.decode(\"utf8\") #\n",
    "# response.close()\n",
    "# # print (mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geturl(page):\n",
    "    if page<2:\n",
    "        url='https://www.si.edu/search/collection-images?edan_q=clay&oa=1&edan_fq%5B0%5D=media_usage:CC0'\n",
    "\n",
    "    else:\n",
    "        url=f'https://www.si.edu/search/collection-images?page={page-1}&edan_q=clay&oa=1&edan_fq%5B0%5D=media_usage:CC0'\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number=range(1,33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in /Users/chakim2/anaconda3/lib/python3.11/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/chakim2/anaconda3/lib/python3.11/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/chakim2/anaconda3/lib/python3.11/site-packages (from html5lib) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=pd.DataFrame()\n",
    "\n",
    "for i in range(1,100):\n",
    "    url_now=geturl(i)\n",
    "    response = urllib.request.urlopen(url_now)\n",
    "    html = response.read()\n",
    "    mystr = html.decode(\"utf8\") \n",
    "    response.close()\n",
    "    soup = BeautifulSoup(mystr,\"html5lib\")\n",
    "\n",
    "    each_elements = soup.find_all('div', class_='node node--teaser node--teaser-long')\n",
    "    each_elements\n",
    "\n",
    "    for div in each_elements:\n",
    "        title = div.select_one('.title.delta').get_text(strip=True)\n",
    "        img_tag = div.select_one('img')\n",
    "        link = img_tag['src']\n",
    "\n",
    "        titles.append(title)\n",
    "        links.append(link)\n",
    "    df_temp = pd.DataFrame({'title': titles, 'link': links})\n",
    "\n",
    "df_all = pd.concat([df_all, df_temp], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['link'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sel=df_all.drop_duplicates()\n",
    "df_all_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract title and link from each div\n",
    "# for div in each_elements:\n",
    "#     title = div.select_one('.title.delta').get_text(strip=True)\n",
    "#     img_tag = div.select_one('img')\n",
    "#     link = img_tag['src']\n",
    "\n",
    "#     titles.append(title)\n",
    "#     links.append(link)\n",
    "# df_temp = pd.DataFrame({'title': titles, 'link': links})\n",
    "\n",
    "# df_all=pd.concat(df_all,df_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('clayTest_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "acecfa85fbebf4f8dc612730d140efe08aa3b2685349b97e21bf6367c155f4e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
